{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from numpy import pad\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from timm.models.layers import trunc_normal_\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "HIDDEN_DIM = 256\n",
    "NUM_PROPOSALS = 100\n",
    "CONV_KERNEL_SIZE_1D = 3\n",
    "\n",
    "class MultiHeadCrossAtten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiHeadCrossAtten, self).__init__()\n",
    "        self.hidden_dim = HIDDEN_DIM\n",
    "        self.num_proposals = NUM_PROPOSALS\n",
    "        self.conv_kernel_size_1d = CONV_KERNEL_SIZE_1D\n",
    "\n",
    "        self.atten = nn.MultiheadAttention(embed_dim=self.hidden_dim * 1**2, num_heads=8, dropout=0.0)\n",
    "        self.f_norm = nn.LayerNorm(self.hidden_dim)\n",
    "\n",
    "    def forward(self, query, value):\n",
    "        # torch.cuda.synchronize()\n",
    "        query = query.permute(1, 0, 2)\n",
    "        value = value.permute(1, 0, 2)\n",
    "\n",
    "        # TODO: check\n",
    "        out = self.atten(query, value, value)[0]\n",
    "        out = out.permute(1, 0, 2)\n",
    "        out = self.f_norm(out)\n",
    "        # torch.cuda.synchronize()\n",
    "        return out\n",
    "\n",
    "\n",
    "class DyConvAtten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DyConvAtten, self).__init__()\n",
    "        self.hidden_dim = HIDDEN_DIM\n",
    "        self.num_proposals = NUM_PROPOSALS\n",
    "        self.conv_kernel_size_1d = CONV_KERNEL_SIZE_1D\n",
    "\n",
    "        self.f_linear = nn.Linear(self.hidden_dim, self.num_proposals * self.conv_kernel_size_1d)\n",
    "        self.f_norm = nn.LayerNorm(self.hidden_dim)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        # print(\"init weights\")\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "\n",
    "    def forward(self, f, k):\n",
    "        # torch.cuda.synchronize()\n",
    "        # f: [B, N, C]\n",
    "        # k: [B, N, C * K * K]\n",
    "        B = f.shape[0]\n",
    "        weight = self.f_linear(f)\n",
    "        weight = weight.view(B, self.num_proposals, self.num_proposals, self.conv_kernel_size_1d)\n",
    "        res = []\n",
    "        for i in range(B):\n",
    "            # input: [1, N, C * K * K]\n",
    "            # weight: [N, N, convK]\n",
    "            # output: [1, N, C * K * K]\n",
    "            out = F.conv1d(input=k.unsqueeze(1)[i], weight=weight[i], padding='same')\n",
    "            res.append(out)\n",
    "        # [B, N, C * K * K] \n",
    "        f_tmp = torch.cat(res, dim=0) #.permute(1, 0, 2).reshape(self.num_proposals, B, self.hidden_dim)\n",
    "        f_tmp = self.f_norm(f_tmp)\n",
    "        # [N, B, C * K * K]\n",
    "        # f_tmp = f_tmp.permute(1, 0, 2)\n",
    "        # torch.cuda.synchronize()\n",
    "        return f_tmp\n",
    "\n",
    "\n",
    "class DySepConvAtten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DySepConvAtten, self).__init__()\n",
    "        self.hidden_dim = HIDDEN_DIM\n",
    "        self.num_proposals = NUM_PROPOSALS\n",
    "        self.kernel_size = CONV_KERNEL_SIZE_1D\n",
    "\n",
    "        # self.depth_weight_linear = nn.Linear(hidden_dim, kernel_size)\n",
    "        # self.point_weigth_linear = nn.Linear(hidden_dim, num_proposals)\n",
    "        self.weight_linear = nn.Linear(self.hidden_dim, self.num_proposals + self.kernel_size)\n",
    "        self.norm = nn.LayerNorm(self.hidden_dim)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        # print(\"init weights\")\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "\n",
    "\n",
    "    def forward(self, query, value):\n",
    "        # torch.cuda.synchronize()\n",
    "        assert query.shape == value.shape\n",
    "        B, N, C = query.shape\n",
    "        \n",
    "        # dynamic depth-wise conv\n",
    "        # dy_depth_conv_weight = self.depth_weight_linear(query).view(B, self.num_proposals, 1,self.kernel_size) # B, N, 1, K\n",
    "        # dy_point_conv_weight = self.point_weigth_linear(query).view(B, self.num_proposals, self.num_proposals, 1)\n",
    "\n",
    "        dy_conv_weight = self.weight_linear(query)\n",
    "        # dy_depth_conv_weight = dy_conv_weight[:, :, :self.kernel_size].view(B,self.num_proposals,1,self.kernel_size)\n",
    "        # dy_point_conv_weight = dy_conv_weight[:, :, self.kernel_size:].view(B,self.num_proposals,self.num_proposals,1)\n",
    "\n",
    "        res = []\n",
    "        value = value.unsqueeze(1)\n",
    "        for i in range(B):\n",
    "            # input: [1, N, C]\n",
    "            # weight: [N, 1, K]\n",
    "            # output: [1, N, C]\n",
    "            # \n",
    "            # dy_depth_conv_weight[i]\n",
    "            out = F.relu(F.conv1d(input=value[i], weight=dy_conv_weight[i, :, :self.kernel_size].view(self.num_proposals,1,self.kernel_size), groups=N, padding=\"same\"))\n",
    "            # input: [1, N, C]\n",
    "            # weight: [N, N, 1]\n",
    "            # output: [1, N, C]\n",
    "            # \n",
    "            # dy_point_conv_weight[i]\n",
    "            out = F.conv1d(input=out, weight=dy_conv_weight[i, :, self.kernel_size:].view(self.num_proposals,self.num_proposals,1), padding='same')\n",
    "\n",
    "            res.append(out)\n",
    "        point_out = torch.cat(res, dim=0)\n",
    "        point_out = self.norm(point_out)\n",
    "        # torch.cuda.synchronize()\n",
    "        return point_out\n",
    "\n",
    "\n",
    "class DyDepthwiseConvAtten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DyDepthwiseConvAtten, self).__init__()\n",
    "        self.hidden_dim = HIDDEN_DIM\n",
    "        self.num_proposals = NUM_PROPOSALS\n",
    "        self.kernel_size = CONV_KERNEL_SIZE_1D\n",
    "\n",
    "        # self.depth_weight_linear = nn.Linear(hidden_dim, kernel_size)\n",
    "        # self.point_weigth_linear = nn.Linear(hidden_dim, num_proposals)\n",
    "        self.weight_linear = nn.Linear(self.hidden_dim, self.kernel_size)\n",
    "        self.norm = nn.LayerNorm(self.hidden_dim)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        # print(\"init weights\")\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "\n",
    "\n",
    "    def forward(self, query, value):\n",
    "        # torch.cuda.synchronize()\n",
    "        assert query.shape == value.shape\n",
    "        B, N, C = query.shape\n",
    "        \n",
    "        # dynamic depth-wise conv\n",
    "        # dy_depth_conv_weight = self.depth_weight_linear(query).view(B, self.num_proposals, 1,self.kernel_size) # B, N, 1, K\n",
    "        # dy_point_conv_weight = self.point_weigth_linear(query).view(B, self.num_proposals, self.num_proposals, 1)\n",
    "        dy_conv_weight = self.weight_linear(query).view(B,self.num_proposals,1,self.kernel_size)\n",
    "        # dy_depth_conv_weight = dy_conv_weight[:, :, :self.kernel_size].view(B,self.num_proposals,1,self.kernel_size)\n",
    "        # dy_point_conv_weight = dy_conv_weight[:, :, self.kernel_size:].view(B,self.num_proposals,self.num_proposals,1)\n",
    "\n",
    "        res = []\n",
    "        value = value.unsqueeze(1)\n",
    "        for i in range(B):\n",
    "            # input: [1, N, C]\n",
    "            # weight: [N, 1, K]\n",
    "            # output: [1, N, C]\n",
    "            out = F.conv1d(input=value[i], weight=dy_conv_weight[i], groups=N, padding=\"same\")\n",
    "            # input: [1, N, C]\n",
    "            # weight: [N, N, 1]\n",
    "            # output: [1, N, C]\n",
    "            # out = F.conv1d(input=out, weight=dy_point_conv_weight[i], padding='same')\n",
    "            res.append(out)\n",
    "        point_out = torch.cat(res, dim=0)\n",
    "        point_out = self.norm(point_out)\n",
    "        # torch.cuda.synchronize()\n",
    "        return point_out\n",
    "\n",
    "\n",
    "class DyPointwiseConvAtten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DyPointwiseConvAtten, self).__init__()\n",
    "        self.hidden_dim = HIDDEN_DIM\n",
    "        self.num_proposals = NUM_PROPOSALS\n",
    "        self.kernel_size = CONV_KERNEL_SIZE_1D\n",
    "\n",
    "        # self.depth_weight_linear = nn.Linear(hidden_dim, kernel_size)\n",
    "        # self.point_weigth_linear = nn.Linear(hidden_dim, num_proposals)\n",
    "        self.weight_linear = nn.Linear(self.hidden_dim, self.num_proposals)\n",
    "        self.norm = nn.LayerNorm(self.hidden_dim)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        # print(\"init weights\")\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "\n",
    "\n",
    "    def forward(self, query, value):\n",
    "        # torch.cuda.synchronize()\n",
    "        assert query.shape == value.shape\n",
    "        B, N, C = query.shape\n",
    "        \n",
    "        # dynamic depth-wise conv\n",
    "        # dy_depth_conv_weight = self.depth_weight_linear(query).view(B, self.num_proposals, 1,self.kernel_size) # B, N, 1, K\n",
    "        # dy_point_conv_weight = self.point_weigth_linear(query).view(B, self.num_proposals, self.num_proposals, 1)\n",
    "\n",
    "        dy_conv_weight = self.weight_linear(query).view(B,self.num_proposals,self.num_proposals,1)\n",
    "\n",
    "        res = []\n",
    "        value = value.unsqueeze(1)\n",
    "        for i in range(B):\n",
    "            # input: [1, N, C]\n",
    "            # weight: [N, 1, K]\n",
    "            # output: [1, N, C]\n",
    "            # out = F.relu(F.conv1d(, weight=dy_depth_conv_weight[i], groups=N, padding=\"same\"))\n",
    "            # input: [1, N, C]\n",
    "            # weight: [N, N, 1]\n",
    "            # output: [1, N, C]\n",
    "            out = F.conv1d(input=value[i], weight=dy_conv_weight[i], padding='same')\n",
    "\n",
    "            res.append(out)\n",
    "        point_out = torch.cat(res, dim=0)\n",
    "        point_out = self.norm(point_out)\n",
    "        # torch.cuda.synchronize()\n",
    "        return point_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::div encountered 2 time(s)\n",
      "Unsupported operator aten::mul encountered 5 time(s)\n",
      "Unsupported operator aten::softmax encountered 1 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "atten.out_proj\n",
      "Unsupported operator aten::_convolution_mode encountered 1 time(s)\n",
      "Unsupported operator aten::_convolution_mode encountered 2 time(s)\n",
      "Unsupported operator aten::_convolution_mode encountered 1 time(s)\n",
      "Unsupported operator aten::_convolution_mode encountered 1 time(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MHCA flops counter: \n",
      "31462400\n",
      "Counter({'linear': 26214400, 'bmm': 5120000, 'layer_norm': 128000})\n",
      "DCA flops counter: \n",
      "15488000.0\n",
      "Counter({'linear': 7680000, 'layer_norm': 128000}) conv:  7680000.0\n",
      "DSCA flops counter: \n",
      "5401600.0\n",
      "Counter({'linear': 2636800, 'layer_norm': 128000}) depthwise:  76800.0 pointwise:  2560000.0\n",
      "DDCA flops counter: \n",
      "281600.0\n",
      "Counter({'layer_norm': 128000, 'linear': 76800}) depthwise:  76800.0\n",
      "DPCA flops counter: \n",
      "5248000.0\n",
      "Counter({'linear': 2560000, 'layer_norm': 128000}) pointwise:  2560000.0\n"
     ]
    }
   ],
   "source": [
    "# FLOPs\n",
    "from fvcore.nn import FlopCountAnalysis\n",
    "from fvcore.nn import ActivationCountAnalysis\n",
    "\n",
    "from ptflops import get_model_complexity_info\n",
    "\n",
    "q = torch.rand((1, NUM_PROPOSALS, HIDDEN_DIM))\n",
    "v = torch.rand((1, NUM_PROPOSALS, HIDDEN_DIM))\n",
    "\n",
    "MHCA = MultiHeadCrossAtten()\n",
    "DCA = DyConvAtten()\n",
    "DSCA = DySepConvAtten()\n",
    "DDCA = DyDepthwiseConvAtten()\n",
    "DPCA = DyPointwiseConvAtten()\n",
    "\n",
    "flops = FlopCountAnalysis(MHCA, (q, v))\n",
    "print(\"MHCA flops counter: \")\n",
    "print(flops.total())\n",
    "print(flops.by_operator())\n",
    "\n",
    "flops = FlopCountAnalysis(DCA, (q, v))\n",
    "print(\"DCA flops counter: \")\n",
    "conv = nn.Conv1d(in_channels=NUM_PROPOSALS, out_channels=NUM_PROPOSALS, kernel_size=CONV_KERNEL_SIZE_1D, bias=False, padding='same')\n",
    "macs, _ = get_model_complexity_info(conv, (NUM_PROPOSALS, HIDDEN_DIM), as_strings=False, print_per_layer_stat=False, verbose=True)\n",
    "print(flops.total() + macs)\n",
    "print(flops.by_operator(), \"conv: \", macs)\n",
    "\n",
    "flops = FlopCountAnalysis(DSCA, (q, v))\n",
    "print(\"DSCA flops counter: \")\n",
    "depthwise_conv = nn.Conv1d(in_channels=NUM_PROPOSALS, out_channels=NUM_PROPOSALS, kernel_size=CONV_KERNEL_SIZE_1D, bias=False, groups=NUM_PROPOSALS, padding='same')\n",
    "macs_depthwise, _ = get_model_complexity_info(depthwise_conv, (NUM_PROPOSALS, HIDDEN_DIM), as_strings=False, print_per_layer_stat=False, verbose=True)\n",
    "pointwise_conv = nn.Conv1d(in_channels=NUM_PROPOSALS, out_channels=NUM_PROPOSALS, kernel_size=1, bias=False, padding='same')\n",
    "macs_pointwise, _ = get_model_complexity_info(pointwise_conv, (NUM_PROPOSALS, HIDDEN_DIM), as_strings=False, print_per_layer_stat=False, verbose=True)\n",
    "print(flops.total() + macs_depthwise + macs_pointwise)\n",
    "print(flops.by_operator(), \"depthwise: \", macs_depthwise, \"pointwise: \", macs_pointwise)\n",
    "\n",
    "flops = FlopCountAnalysis(DDCA, (q, v))\n",
    "print(\"DDCA flops counter: \")\n",
    "print(flops.total() + macs_depthwise)\n",
    "print(flops.by_operator(), \"depthwise: \", macs_depthwise,)\n",
    "\n",
    "flops = FlopCountAnalysis(DPCA, (q, v))\n",
    "print(\"DPCA flops counter: \")\n",
    "print(flops.total() + macs_pointwise)\n",
    "print(flops.by_operator(), \"pointwise: \", macs_pointwise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                       cudaEventDestroy        26.96%     572.000us        26.96%     572.000us       6.500us       0.000us         0.00%       0.000us       0.000us            88  \n",
      "                                        cudaEventRecord        13.95%     296.000us        13.95%     296.000us       3.326us       0.000us         0.00%       0.000us       0.000us            89  \n",
      "                                aten::cudnn_convolution        10.18%     216.000us        16.31%     346.000us     346.000us     296.000us        20.32%     338.000us     338.000us             1  \n",
      "                                        cudaEventCreate         5.04%     107.000us         5.04%     107.000us       1.216us       0.000us         0.00%       0.000us       0.000us            88  \n",
      "                                               aten::mm         4.90%     104.000us         6.74%     143.000us     143.000us     130.000us         8.92%     130.000us     130.000us             1  \n",
      "                                       cudaLaunchKernel         4.15%      88.000us         4.15%      88.000us      11.000us       0.000us         0.00%       0.000us       0.000us             8  \n",
      "                                            aten::empty         3.30%      70.000us         6.08%     129.000us      25.800us      82.000us         5.63%      82.000us      16.400us             5  \n",
      "                                       aten::as_strided         3.16%      67.000us         6.69%     142.000us      17.750us      76.000us         5.22%      76.000us       9.500us             8  \n",
      "                                aten::native_layer_norm         2.54%      54.000us         8.67%     184.000us     184.000us     116.000us         7.96%     176.000us     176.000us             1  \n",
      "                                             aten::view         2.50%      53.000us         4.43%      94.000us      18.800us      55.000us         3.77%      55.000us      11.000us             5  \n",
      "                                           aten::linear         2.07%      44.000us        20.88%     443.000us     443.000us      63.000us         4.32%     422.000us     422.000us             1  \n",
      "                                        aten::unsqueeze         1.84%      39.000us         5.28%     112.000us      37.333us      65.000us         4.46%      89.000us      29.667us             3  \n",
      "                                             aten::_cat         1.84%      39.000us         8.39%     178.000us     178.000us      84.000us         5.77%     170.000us     170.000us             1  \n",
      "                                             aten::add_         1.65%      35.000us         2.64%      56.000us      56.000us      49.000us         3.36%      49.000us      49.000us             1  \n",
      "                                     aten::_convolution         1.51%      32.000us        23.70%     503.000us     503.000us      64.000us         4.39%     496.000us     496.000us             1  \n",
      "                                          aten::resize_         1.46%      31.000us         2.59%      55.000us      18.333us      31.000us         2.13%      31.000us      10.333us             3  \n",
      "                                           aten::select         1.37%      29.000us         3.58%      76.000us      38.000us      46.000us         3.16%      60.000us      30.000us             2  \n",
      "                                           aten::matmul         1.27%      27.000us        11.26%     239.000us     239.000us      57.000us         3.91%     231.000us     231.000us             1  \n",
      "                                                aten::t         1.18%      25.000us         4.10%      87.000us      87.000us      33.000us         2.26%      79.000us      79.000us             1  \n",
      "                                        cudaMemcpyAsync         1.04%      22.000us         1.04%      22.000us      22.000us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                              aten::cat         0.94%      20.000us         9.75%     207.000us     207.000us      28.000us         1.92%     198.000us     198.000us             1  \n",
      "                                            aten::slice         0.94%      20.000us         2.12%      45.000us      45.000us      29.000us         1.99%      37.000us      37.000us             1  \n",
      "                                          aten::squeeze         0.85%      18.000us         2.03%      43.000us      43.000us      26.000us         1.78%      35.000us      35.000us             1  \n",
      "                                        aten::transpose         0.80%      17.000us         2.54%      54.000us      54.000us      25.000us         1.72%      46.000us      46.000us             1  \n",
      "                                     aten::_unsafe_view         0.75%      16.000us         1.89%      40.000us      40.000us      22.000us         1.51%      31.000us      31.000us             1  \n",
      "                                aten::_convolution_mode         0.66%      14.000us        24.74%     525.000us     525.000us      21.000us         1.44%     517.000us     517.000us             1  \n",
      "                                  cudaDeviceSynchronize         0.61%      13.000us         0.61%      13.000us      13.000us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                           aten::conv1d         0.57%      12.000us        25.68%     545.000us     545.000us      20.000us         1.37%     537.000us     537.000us             1  \n",
      "                                           aten::narrow         0.57%      12.000us         3.06%      65.000us      65.000us      20.000us         1.37%      57.000us      57.000us             1  \n",
      "                                       aten::layer_norm         0.57%      12.000us         9.61%     204.000us     204.000us      19.000us         1.30%     195.000us     195.000us             1  \n",
      "                                  cudaFuncGetAttributes         0.38%       8.000us         0.38%       8.000us       8.000us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                   cudaFuncSetAttribute         0.28%       6.000us         0.28%       6.000us       1.000us       0.000us         0.00%       0.000us       0.000us             6  \n",
      "cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFla...         0.19%       4.000us         0.19%       4.000us       2.000us       0.000us         0.00%       0.000us       0.000us             2  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 2.122ms\n",
      "Self CUDA time total: 1.457ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Latency\n",
    "import torch\n",
    "q = torch.rand((1, NUM_PROPOSALS, HIDDEN_DIM), requires_grad=False).cuda()\n",
    "v = torch.rand((1, NUM_PROPOSALS, HIDDEN_DIM), requires_grad=False).cuda()\n",
    "\n",
    "# MHCA = MultiHeadCrossAtten().cuda()\n",
    "DCA = DyConvAtten().cuda()\n",
    "# DSCA = DySepConvAtten().cuda()\n",
    "# DDCA = DyDepthwiseConvAtten().cuda()\n",
    "# DPCA = DyPointwiseConvAtten().cuda()\n",
    "\n",
    "# warm up\n",
    "# o = MHCA(q, v)\n",
    "o = DCA(q, v)\n",
    "# o = DSCA(q, v)\n",
    "# o = DDCA(q, v)\n",
    "# o = DPCA(q, v)\n",
    "\n",
    "# with torch.autograd.profiler.profile(enabled=True, use_cuda=True, record_shapes=False) as prof:\n",
    "#     o = MHCA(q, v)\n",
    "# # NOTE: some columns were removed for brevity\n",
    "# print(prof.key_averages().table(sort_by=\"self_cpu_time_total\"))\n",
    "\n",
    "with torch.autograd.profiler.profile(enabled=True, use_cuda=True, record_shapes=False) as prof:\n",
    "    o = DCA(q, v)\n",
    "# NOTE: some columns were removed for brevity\n",
    "print(prof.key_averages().table(sort_by=\"self_cpu_time_total\"))\n",
    "\n",
    "# with torch.autograd.profiler.profile(enabled=True, use_cuda=True, record_shapes=False) as prof:\n",
    "#     o = DSCA(q, v)\n",
    "# # NOTE: some columns were removed for brevity\n",
    "# print(prof.key_averages().table(sort_by=\"self_cpu_time_total\"))\n",
    "\n",
    "# with torch.autograd.profiler.profile(enabled=True, use_cuda=True, record_shapes=False) as prof:\n",
    "#     o = DDCA(q, v)\n",
    "# # NOTE: some columns were removed for brevity\n",
    "# print(prof.key_averages().table(sort_by=\"self_cpu_time_total\"))\n",
    "\n",
    "# with torch.autograd.profiler.profile(enabled=True, use_cuda=True, record_shapes=False) as prof:\n",
    "#     o = DPCA(q, v)\n",
    "# # NOTE: some columns were removed for brevity\n",
    "# print(prof.key_averages().table(sort_by=\"self_cpu_time_total\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('YOSO')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "18d1c34aac4e50ff4dc786cc8ed509f79524cdbbbd585bbcbda27df53377b6a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
